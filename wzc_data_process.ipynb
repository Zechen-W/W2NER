{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "data = json.load(open('./output.json'))\n",
    "json.dump(data, open('./output.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 生成EE的数据集\n",
    "import numpy as np\n",
    "import json\n",
    "data = json.load(open('./data/ee/data_label.json'))\n",
    "to_save=[]\n",
    "for dialog in data:\n",
    "    for turn in dialog['content']:\n",
    "        keys = list(turn.keys())[:2]\n",
    "        t_ents = turn['info']['ents']\n",
    "        \n",
    "        item1={\n",
    "            'sentence':' '.join(turn[keys[0]]).split(),\n",
    "            'ner':[]\n",
    "        }\n",
    "        item2={\n",
    "            'sentence':' '.join(turn[keys[1]]).split(),\n",
    "            'ner':[]\n",
    "        }\n",
    "\n",
    "        for ent in t_ents:\n",
    "            ner = {\n",
    "                'index':np.arange(ent['pos'][0][1], ent['pos'][0][2]).tolist(),\n",
    "                'type':ent['type']\n",
    "            }\n",
    "\n",
    "            if ent['pos'][0][0] == 1:\n",
    "                item1['ner'].append(ner)\n",
    "            elif ent['pos'][0][0] == 2:\n",
    "                item2['ner'].append(ner)\n",
    "        \n",
    "        if item1['ner']:\n",
    "            to_save.append(item1)\n",
    "        if item2['ner']:\n",
    "            to_save.append(item2)\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(to_save)\n",
    "np.random.shuffle(to_save)\n",
    "n = len(to_save)\n",
    "json.dump(to_save[:int(.8*n)], open('./data/seretod/train.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "json.dump(to_save[int(.8*n):int(.9*n)], open('./data/seretod/dev.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "json.dump(to_save[int(.9*n):], open('./data/seretod/test.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "# json.dump(to_save, open('./data/all_data.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.71959678165171"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 用基线的测试方法测试此模型的输出结果\n",
    "task = 'sf'\n",
    "import json \n",
    "import re\n",
    "labels = json.load(open(f'./data/{task}/test.json', encoding='utf8'))\n",
    "bio_l = []\n",
    "texts = []\n",
    "for sent in labels:\n",
    "    texts.append(''.join(sent['sentence']))\n",
    "    res = ['O']*len(sent['sentence'])\n",
    "    for ent in sent['ner']:\n",
    "        for i in ent['index']:\n",
    "            res[i] = f'I-{ent[\"type\"]}'\n",
    "        res[ent['index'][0]] = f'B-{ent[\"type\"]}'\n",
    "\n",
    "    bio_l.append(res)\n",
    "\n",
    "output = json.load(open(f'./output/{task}/output.json', encoding='utf8'))\n",
    "bio_o = []\n",
    "for sent in output:\n",
    "    res = ['O']*len(sent['sentence'])\n",
    "    text = ''.join(sent['sentence'])\n",
    "    for ent in sent['entity']:\n",
    "        label = ''.join(ent['text'])\n",
    "        span = re.search(label, text).span()\n",
    "        for i in range(*span):\n",
    "            res[i] = f\"I-{ent['type'].upper()}\"\n",
    "        res[span[0]] = f\"B-{ent['type'].upper()}\"\n",
    "    bio_o.append(res)\n",
    "\n",
    "\n",
    "from seqeval.metrics import f1_score as span_f1_score\n",
    "from seqeval.scheme import IOB2\n",
    "micro_f1 = span_f1_score(bio_l, bio_o, mode='strict', scheme=IOB2) * 100.0\n",
    "micro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = []\n",
    "for text, label, output in zip(texts, bio_l, bio_o):\n",
    "    if label!=output:\n",
    "        cases.append({\n",
    "            'text': text,\n",
    "            'label': ' '.join(label),\n",
    "            'output': ' '.join(output)\n",
    "        })\n",
    "json.dump(cases, open('./case.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 处理生成SF的数据集\n",
    "import numpy as np\n",
    "import json\n",
    "data = json.load(open('./data/ee/data_label.json'))\n",
    "to_save=[]\n",
    "for dialog in data:\n",
    "    for turn in dialog['content']:\n",
    "        keys = list(turn.keys())[:2]\n",
    "        t_triples = turn['info']['triples']\n",
    "        \n",
    "        item1={\n",
    "            'sentence':' '.join(turn[keys[0]]).split(),\n",
    "            'ner':[]\n",
    "        }\n",
    "        item2={\n",
    "            'sentence':' '.join(turn[keys[1]]).split(),\n",
    "            'ner':[]\n",
    "        }\n",
    "\n",
    "        for triple in t_triples:\n",
    "            ner = {\n",
    "                'index':np.arange(triple['pos'][1], triple['pos'][2]).tolist(),\n",
    "                'type':triple['prop']\n",
    "            }\n",
    "\n",
    "            if triple['pos'][0] == 1:\n",
    "                item1['ner'].append(ner)\n",
    "            elif triple['pos'][0] == 2:\n",
    "                item2['ner'].append(ner)\n",
    "        \n",
    "        if item1['ner']:\n",
    "            to_save.append(item1)\n",
    "        if item2['ner']:\n",
    "            to_save.append(item2)\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(to_save)\n",
    "np.random.shuffle(to_save)\n",
    "n = len(to_save)\n",
    "json.dump(to_save[:int(.8*n)], open('./data/sf/train.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "json.dump(to_save[int(.8*n):int(.9*n)], open('./data/sf/dev.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "json.dump(to_save[int(.9*n):], open('./data/sf/test.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "# json.dump(to_save, open('./data/all_data.json', 'w', encoding='utf8'), indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seretod')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71c3eea4cf5c1ab773b4d45c468614636ae3e3c5339ee60654fd270fba2a0266"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
